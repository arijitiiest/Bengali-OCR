{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bangla Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog, local_binary_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    height = 32\n",
    "    width = 32\n",
    "    for file_name in os.listdir(path):\n",
    "        file_path = path + '/' + file_name\n",
    "        for img_name in os.listdir(file_path):\n",
    "            if not img_name.startswith('.'):\n",
    "                if img_name.endswith('.png'):\n",
    "                    img = cv2.imread(file_path + '/' + img_name)\n",
    "                    new_img = cv2.resize(img, (height, width))\n",
    "                    images.append(new_img)\n",
    "                    labels.append(file_name)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Load Extracted Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature(feature, name):\n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open('cache/' + name + '.pkl', 'wb') as fp:\n",
    "        pickle.dump(csr_matrix(feature), fp)\n",
    "    \n",
    "    print(f'Feature saved with name cache/{name}.pkl')\n",
    "\n",
    "def load_feature(feature_name):\n",
    "    return pickle.load(open(feature_name, 'rb')).A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Load PCA fit components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pca(pca_data, name):\n",
    "    pickle.dump(pca_data, open('pca/' + name + '.pkl', 'wb'))\n",
    "    print(f'PCA data saved with name pca/{name}.pkl')\n",
    "    \n",
    "def load_pca(pca_name):\n",
    "    return pickle.load(open(pca_nam, 'rb')).A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Load Trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    filename = input('Enter model file name:')\n",
    "    pickle.dump(model, open('models/'+filename + '.pkl', 'wb'))\n",
    "    print(f'Successfully saved model in models/{filename}.pkl')\n",
    "\n",
    "def load_model(model_name):\n",
    "    return pickle.load(open(model_name, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog(images, name='hog', save=False):\n",
    "    cell_size = (4, 4)    # h x w in pixels\n",
    "    block_size = (2, 2)     # h x w in cells\n",
    "    nbins = 9\n",
    "    \n",
    "    # winSize is the size of the image cropped to an multiple of the cell size\n",
    "    # cell_size is the size of the cells of the img patch over which to calculate the histograms\n",
    "    # block_size is the number of cells which fit in the patch\n",
    "    hog_desc = cv2.HOGDescriptor(_winSize=(images[0].shape[1] // cell_size[1] * cell_size[1],\n",
    "                                              images[0].shape[0] // cell_size[0] * cell_size[0]),\n",
    "                                    _blockSize=(block_size[1] * cell_size[1],\n",
    "                                                block_size[0] * cell_size[0]),\n",
    "                                    _blockStride=(cell_size[1], cell_size[0]),\n",
    "                                    _cellSize=(cell_size[1], cell_size[0]),\n",
    "                                    _nbins=nbins)\n",
    "    \n",
    "    def get_image_hog(image):\n",
    "        # HOG feature\n",
    "        f = hog_desc.compute(image)\n",
    "        \n",
    "        res = np.array(f)\n",
    "        return res.flatten()\n",
    "    \n",
    "    # HOG for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        f = get_image_hog(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY))\n",
    "        features.append(f)\n",
    "    \n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Binary Pattern (LBP) Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lbp(images, name='lbp', save=False):\n",
    "    result = np.array([local_binary_pattern(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 10, 3).flatten() for img in images])\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sift(images, name='sift', save=False):\n",
    "    \n",
    "    # SIFT descriptor for 1 image\n",
    "    def get_image_sift(image, vector_size=15):\n",
    "        alg = cv2.xfeatures2d.SIFT_create()\n",
    "        kps = alg.detect(image, None)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 128\n",
    "        needed_size = (vector_size * 128)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "            \n",
    "        return dsc\n",
    "    \n",
    "    # SIFT descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_sift(img)\n",
    "        features.append(dsc)\n",
    "\n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattened Image feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened(images, name='flatten', save=False):\n",
    "    \n",
    "    def get_image_flatten(image):\n",
    "        return cv2.cvtColor(image,  cv2.COLOR_RGB2GRAY).flatten()\n",
    "        \n",
    "        \n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_flatten(img)\n",
    "        features.append(dsc)\n",
    "\n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(features, horizontal=True):\n",
    "    \"\"\"\n",
    "    Array of features [f1, f2, f3] where each fi is a feature set \n",
    "    eg. f1=rgb_flat, f2=SIFT, etc.\n",
    "    \"\"\"\n",
    "    if horizontal:\n",
    "        return np.hstack(features)\n",
    "    else:\n",
    "        return np.vstack(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_features_minmax(train, test):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    norm_train = min_max_scaler.fit_transform(train)\n",
    "    norm_test = min_max_scaler.transform(test)\n",
    "    \n",
    "    return norm_train, norm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_features_zscore(train, test):\n",
    "    min_max_scaler = preprocessing.StandardScaler()\n",
    "    norm_train = min_max_scaler.fit_transform(train)\n",
    "    norm_test = min_max_scaler.transform(test)\n",
    "    \n",
    "    return norm_train, norm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_x, train_y, model_name='NB', validation=None):\n",
    "    \"\"\"\n",
    "    Possible model names: ['RF', 'SVM', 'XGB', 'KNN']\n",
    "    default = 'NB'\n",
    "    \n",
    "    validation: (val_x, val_y) tupple for validation accuracy score.\n",
    "    \n",
    "    return: trained model\n",
    "    \"\"\"\n",
    "    model = None\n",
    "    if model_name == 'SVM':\n",
    "        model = svm.SVC(gamma='scale', probability=True)\n",
    "    elif model_name == 'XGB':\n",
    "        model = XGBClassifier(n_estimators=200, max_depth=5, n_jobs=2)\n",
    "#         model = XGBClassifier()\n",
    "    elif model_name == 'RF':\n",
    "        model = RandomForestClassifier(n_estimators=200, max_depth=10)\n",
    "    elif model_name == 'KNN':\n",
    "        model = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "    else:\n",
    "        model = GaussianNB()\n",
    "    \n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    if validation is not None:\n",
    "        y_hat = model.predict(validation[0])\n",
    "        acc = metrics.accuracy_score(validation[1], y_hat)\n",
    "        print(f\"Validation Accuracy in '{model_name}' = {acc}\")\n",
    "        cm = metrics.confusion_matrix(validation[1], y_hat)\n",
    "        print(cm)\n",
    "        recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "        precision = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "        f1 = 2*(precision*recall)/(precision+recall)\n",
    "        print(f\"Recall in '{model_name}' = {recall}\")\n",
    "        print(f\"Precision in '{model_name}' = {precision}\")\n",
    "        print(f\"F1 Score in '{model_name}' = {f1}\")\n",
    "               \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_x, full_data_y = read_images('BanglaLekha-Isolated/Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size :  (166105, 32, 32, 3) (166105,)\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset size : \", full_data_x.shape, full_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Image size:  (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"One Image size: \", full_data_x[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, val_imgs, train_y, val_y = train_test_split(full_data_x, full_data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data : (132884, 32, 32, 3)        Label:  (132884,)\n",
      "Validation data : (33221, 32, 32, 3)    Label:  (33221,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data :\", train_imgs.shape, \"       Label: \", train_y.shape) \n",
    "print(\"Validation data :\", val_imgs.shape, \"   Label: \", val_y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save train, validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/train_imgs.npy', train_imgs)\n",
    "np.save('data/train_y.npy', train_y)\n",
    "np.save('data/val_imgs.npy', val_imgs)\n",
    "np.save('data/val_y.npy', val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.load('data/train_imgs.npy')\n",
    "train_y = np.load('data/train_y.npy')\n",
    "val_imgs = np.load('data/val_imgs.npy')\n",
    "val_y = np.load('data/val_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 32, 32, 3), (33221, 32, 32, 3), (132884,), (33221,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs.shape, val_imgs.shape, train_y.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,10))\n",
    "plt.imshow(train_imgs[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved with name cache/hog_train.pkl\n",
      "Feature saved with name cache/hog_val.pkl\n"
     ]
    }
   ],
   "source": [
    "hog_train = get_hog(train_imgs, name='hog_train', save=True)\n",
    "hog_val = get_hog(val_imgs, name='hog_val', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_train = load_feature('cache/hog_train.pkl')\n",
    "hog_val = load_feature('cache/hog_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 1764), (33221, 1764))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_train.shape, hog_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved with name cache/lbp_train.pkl\n"
     ]
    }
   ],
   "source": [
    "lbp_train = get_lbp(train_imgs, name='lbp_train', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved with name cache/lbp_val.pkl\n"
     ]
    }
   ],
   "source": [
    "lbp_val = get_lbp(val_imgs, name='lbp_val', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_train = load_feature('cache/lbp_train.pkl')\n",
    "lbp_val = load_feature('cache/lbp_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 1024), (33221, 1024))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbp_train.shape, lbp_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved with name cache/sift_train.pkl\n",
      "Feature saved with name cache/sift_val.pkl\n"
     ]
    }
   ],
   "source": [
    "sift_train = get_sift(train_imgs, name='sift_train', save=True)\n",
    "sift_val = get_sift(val_imgs, name='sift_val', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_train = load_feature('cache/sift_train.pkl')\n",
    "sift_val = load_feature('cache/sift_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 1920), (33221, 1920))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sift_train.shape, sift_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattened image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved with name cache/flatten_train.pkl\n",
      "Feature saved with name cache/flatten_val.pkl\n"
     ]
    }
   ],
   "source": [
    "flatten_train = get_flattened(train_imgs, name='flatten_train', save=True)\n",
    "flatten_val = get_flattened(val_imgs, name='flatten_val', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_train = load_feature('cache/flatten_train.pkl')\n",
    "flatten_val = load_feature('cache/flatten_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 1024), (33221, 1024))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_train.shape, flatten_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Features by PCA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOG PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_hog_train, norm_hog_val = norm_features_minmax(hog_train, hog_val)\n",
    "norm_hog_train, norm_hog_val = norm_features_zscore(hog_train, hog_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca_hog_train = pca.fit_transform(norm_hog_train)\n",
    "pca_hog_val = pca.transform(norm_hog_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cache/pca_hog_train.npy', pca_hog_train)\n",
    "np.save('cache/pca_hog_val.npy', pca_hog_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_hog_train = np.load('cache/pca_hog_train.npy')\n",
    "pca_hog_val = np.load('cache/pca_hog_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 10), (33221, 10))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_hog_train.shape, pca_hog_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LBP PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_lbp_train, norm_lbp_val = norm_features_minmax(lbp_train, lbp_val)\n",
    "norm_lbp_train, norm_lbp_val = norm_features_zscore(lbp_train, lbp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca_lbp_train = pca.fit_transform(norm_lbp_train)\n",
    "pca_lbp_val = pca.transform(norm_lbp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cache/pca_lbp_train.npy', pca_lbp_train)\n",
    "np.save('cache/pca_lbp_val.npy', pca_lbp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lbp_train = np.load('cache/pca_lbp_train.npy')\n",
    "pca_lbp_val = np.load('cache/pca_lbp_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 10), (33221, 10))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_lbp_train.shape, pca_lbp_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIFT PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_sift_train, norm_sift_val = norm_features_minmax(sift_train, sift_val)\n",
    "norm_sift_train, norm_sift_val = norm_features_zscore(sift_train, sift_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca_sift_train = pca.fit_transform(norm_sift_train)\n",
    "pca_sift_val = pca.transform(norm_sift_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-88df71ec0249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cache/pca_sift_train.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_sift_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cache/pca_sift_val.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_sift_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('cache/pca_sift_train.npy', pca_sift_train)\n",
    "np.save('cache/pca_sift_val.npy', pca_sift_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_sift_train = np.load('cache/pca_sift_train.npy')\n",
    "pca_sift_val = np.load('cache/pca_sift_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132884, 5), (33221, 5))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_sift_train.shape, pca_sift_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_x, features_val_x, features_train_y, features_val_y = flatten_train, flatten_val, train_y, val_y\n",
    "features_train_x, features_train_y = shuffle(features_train_x, features_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy in 'RF' = 0.3317479907287559\n",
      "[[ 47   0   1 ...   0   0   0]\n",
      " [  2 183   7 ...   0   0   1]\n",
      " [  0   2 265 ...   0   0  11]\n",
      " ...\n",
      " [  2   0   1 ...   9   1   2]\n",
      " [  0   2  22 ...   0  92   3]\n",
      " [  0   0  44 ...   0   4 173]]\n",
      "Recall in 'RF' = 1.0\n",
      "Precision in 'RF' = 0.9591836734693877\n",
      "F1 Score in 'RF' = 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "model1 = train_model(np.array(features_train_x), features_train_y, model_name='RF', validation=(features_val_x, features_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = train_model(np.array(features_train_x), features_train_y, model_name='SVM', validation=(features_val_x, features_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = train_model(np.array(features_train_x), features_train_y, model_name='XGB', validation=(features_val_x, features_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = train_model(np.array(features_train_x), features_train_y,, model_name='KNN', validation=(features_val_x, features_val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
